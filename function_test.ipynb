{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0711a5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.7.0 to v2.0.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file my_model/epoch=23-step=1200.ckpt`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of data is 1670\n",
      "The cutoff is 167\n",
      "The max of time_idx is 191\n",
      "The context length is 336\n",
      "The predictor length is 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Dew Point</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Condition</th>\n",
       "      <th>val</th>\n",
       "      <th>Building</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-17 00:30:00</td>\n",
       "      <td>59.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.04</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>14.060059</td>\n",
       "      <td>1A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-17 01:30:00</td>\n",
       "      <td>61.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.04</td>\n",
       "      <td>Fog</td>\n",
       "      <td>12.856445</td>\n",
       "      <td>1A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-17 02:30:00</td>\n",
       "      <td>61.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.04</td>\n",
       "      <td>Fog</td>\n",
       "      <td>13.673096</td>\n",
       "      <td>1A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-17 03:30:00</td>\n",
       "      <td>61.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.04</td>\n",
       "      <td>Fog</td>\n",
       "      <td>13.463135</td>\n",
       "      <td>1A</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-17 04:30:00</td>\n",
       "      <td>63.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.01</td>\n",
       "      <td>Fog</td>\n",
       "      <td>13.476563</td>\n",
       "      <td>1A</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>2022-11-24 19:30:00</td>\n",
       "      <td>63.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.10</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2E</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>2022-11-24 20:30:00</td>\n",
       "      <td>63.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.10</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2E</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>2022-11-24 21:30:00</td>\n",
       "      <td>63.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.10</td>\n",
       "      <td>Fair</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2E</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>2022-11-24 22:30:00</td>\n",
       "      <td>63.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.10</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2E</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>2022-11-24 23:30:00</td>\n",
       "      <td>63.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.10</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2E</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1910 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp  Temperature  Dew Point  Humidity  Wind Speed  \\\n",
       "0     2022-11-17 00:30:00         59.0       57.0      94.0         2.0   \n",
       "1     2022-11-17 01:30:00         61.0       59.0      94.0         2.0   \n",
       "2     2022-11-17 02:30:00         61.0       59.0      94.0         4.0   \n",
       "3     2022-11-17 03:30:00         61.0       59.0      94.0         7.0   \n",
       "4     2022-11-17 04:30:00         63.0       59.0      88.0         4.0   \n",
       "...                   ...          ...        ...       ...         ...   \n",
       "1915  2022-11-24 19:30:00         63.0       54.0      72.0         4.0   \n",
       "1916  2022-11-24 20:30:00         63.0       55.0      77.0         2.0   \n",
       "1917  2022-11-24 21:30:00         63.0       54.0      72.0         0.0   \n",
       "1918  2022-11-24 22:30:00         63.0       55.0      77.0         4.0   \n",
       "1919  2022-11-24 23:30:00         63.0       55.0      77.0         7.0   \n",
       "\n",
       "      Pressure      Condition        val Building  time_idx  \n",
       "0        30.04     Light Rain  14.060059       1A         0  \n",
       "1        30.04            Fog  12.856445       1A         1  \n",
       "2        30.04            Fog  13.673096       1A         2  \n",
       "3        30.04            Fog  13.463135       1A         3  \n",
       "4        30.01            Fog  13.476563       1A         4  \n",
       "...        ...            ...        ...      ...       ...  \n",
       "1915     30.10  Partly Cloudy   0.000000       2E       187  \n",
       "1916     30.10  Mostly Cloudy   0.000000       2E       188  \n",
       "1917     30.10           Fair   0.000000       2E       189  \n",
       "1918     30.10         Cloudy   0.000000       2E       190  \n",
       "1919     30.10         Cloudy   0.000000       2E       191  \n",
       "\n",
       "[1910 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from pytorch_forecasting import Baseline, DeepAR, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import NaNLabelEncoder\n",
    "from forecast import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class deepAR_model:\n",
    "    def __init__(self, pl_ckpt, context_length, predictor_length, building):\n",
    "        self.model = DeepAR.load_from_checkpoint(pl_ckpt)\n",
    "        self.building_series = building\n",
    "        self.context_length = context_length\n",
    "        self.predictor_length = predictor_length\n",
    "\n",
    "    def predict(self, history_data):\n",
    "        data = pd.read_csv(history_data)\n",
    "        data = data.drop(['Wind', 'Precip.', 'Wind Gust'], axis=1)\n",
    "        data = data.dropna()\n",
    "        \n",
    "        cutoff = data[\"time_idx\"].max() - self.predictor_length\n",
    "\n",
    "        print(f'The size of data is {len(data[lambda x: x[\"time_idx\"] <= cutoff])}')\n",
    "\n",
    "        print(f'The cutoff is {cutoff}')    # 335\n",
    "        print(f'The max of time_idx is {data[\"time_idx\"].max()}')   # 503\n",
    "        print(f'The context length is {self.context_length}')   # 336\n",
    "        print(f'The predictor length is {self.predictor_length}')   # 168\n",
    "        return data\n",
    "        history = TimeSeriesDataSet(\n",
    "            data[lambda x: x.index <= cutoff],\n",
    "            time_idx=\"time_idx\",\n",
    "            target=\"val\",\n",
    "            categorical_encoders={\"Building\": NaNLabelEncoder().fit(data.Building)},\n",
    "            group_ids=[\"Building\"],\n",
    "            static_categoricals=[\"Building\"],\n",
    "            time_varying_known_reals=[\"Temperature\", \"Humidity\", \"Pressure\"],\n",
    "            allow_missing_timesteps=True,\n",
    "            time_varying_unknown_reals=[\"val\"],\n",
    "            max_encoder_length=self.context_length,\n",
    "            max_prediction_length=self.predictor_length,\n",
    "            train = False\n",
    "        )\n",
    "\n",
    "        test = TimeSeriesDataSet.from_dataset(history, data, min_prediction_idx=cutoff + 1)\n",
    "        batch_size = 128\n",
    "        test_dataloader = test.to_dataloader(train=False, batch_size=batch_size, num_workers=0,\n",
    "                                             batch_sampler='synchronized')\n",
    "\n",
    "        predictions = self.model.predict(test_dataloader)\n",
    "        pred_dict = {}\n",
    "        for idx in range(len(self.building_series)):\n",
    "            pred_dict[self.building_series[idx]] = predictions[idx].tolist()\n",
    "\n",
    "        with open(\"prediction.json\", \"w\") as f:\n",
    "            json.dump(pred_dict, f)\n",
    "\n",
    "csv_path = \"../data/weather/future/predict_data.csv\"\n",
    "model_path = './my_model/epoch=23-step=1200.ckpt'\n",
    "pred_day = str(20221124)\n",
    "num_day_context = 7\n",
    "num_day_pred = 1\n",
    "building = ['1A', '1B', '1C', '1D', '1E', '2A', '2B', '2C', '2D', '2E']\n",
    "model = deepAR_model(model_path, 24 * num_day_context, 24 * num_day_pred, building)\n",
    "\n",
    "data = model.predict(csv_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa0478a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.7.0 to v2.0.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file my_model/epoch=23-step=1200.ckpt`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read csv file from ../data/weather/future/predict_data.csv\n",
      "The size of data is 3350\n",
      "The cutoff is 335\n",
      "The max of time_idx is 503\n",
      "The context length is 336\n",
      "The predictor length is 168\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "filters should not remove entries all entries - check encoder/decoder lengths and lags",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m num_day_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m14\u001b[39m\n\u001b[1;32m      6\u001b[0m num_day_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mpredict_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_day\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_day_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_day_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ECE445/prediction_module/mygitrepo/forecast.py:66\u001b[0m, in \u001b[0;36mpredict_api\u001b[0;34m(model_path, pred_day, num_day_context, num_day_pred, crawl_forecast)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread csv file from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpred_data_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     65\u001b[0m model \u001b[38;5;241m=\u001b[39m deepAR_model(model_path, \u001b[38;5;241m24\u001b[39m \u001b[38;5;241m*\u001b[39m num_day_context, \u001b[38;5;241m24\u001b[39m \u001b[38;5;241m*\u001b[39m num_day_pred, building)\n\u001b[0;32m---> 66\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_data_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pred_data_path\n",
      "File \u001b[0;32m~/ECE445/prediction_module/mygitrepo/my_model/forecast.py:30\u001b[0m, in \u001b[0;36mdeepAR_model.predict\u001b[0;34m(self, history_data)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe context length is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)   \u001b[38;5;66;03m# 336\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe predictor length is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)   \u001b[38;5;66;03m# 168\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mTimeSeriesDataSet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime_idx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_encoders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBuilding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mNaNLabelEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBuilding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBuilding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_categoricals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBuilding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_varying_known_reals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHumidity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPressure\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_missing_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_varying_unknown_reals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_encoder_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_prediction_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor_length\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m test \u001b[38;5;241m=\u001b[39m TimeSeriesDataSet\u001b[38;5;241m.\u001b[39mfrom_dataset(history, data, min_prediction_idx\u001b[38;5;241m=\u001b[39mcutoff \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     45\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/DeepAR_env/lib/python3.9/site-packages/pytorch_forecasting/data/timeseries.py:481\u001b[0m, in \u001b[0;36mTimeSeriesDataSet.__init__\u001b[0;34m(self, data, time_idx, target, group_ids, weight, max_encoder_length, min_encoder_length, min_prediction_idx, min_prediction_length, max_prediction_length, static_categoricals, static_reals, time_varying_known_categoricals, time_varying_known_reals, time_varying_unknown_categoricals, time_varying_unknown_reals, variable_groups, constant_fill_strategy, allow_missing_timesteps, lags, add_relative_time_idx, add_target_scales, add_encoder_length, target_normalizer, categorical_encoders, scalers, randomize_length, predict_mode)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m target \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscalers, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget normalizer is separate and not in scalers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# create index\u001b[39;00m\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# convert to torch tensor for high performance data loading later\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_to_tensors(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/DeepAR_env/lib/python3.9/site-packages/pytorch_forecasting/data/timeseries.py:1290\u001b[0m, in \u001b[0;36mTimeSeriesDataSet._construct_index\u001b[0;34m(self, data, predict_mode)\u001b[0m\n\u001b[1;32m   1281\u001b[0m         missing_groups[\u001b[38;5;28mid\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_values(name, missing_groups[\u001b[38;5;28mid\u001b[39m], inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, group_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1282\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMin encoder length and/or min_prediction_idx and/or min prediction length and/or lags are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoo large for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1289\u001b[0m     )\n\u001b[0;32m-> 1290\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;28mlen\u001b[39m(df_index) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1292\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilters should not remove entries all entries - check encoder/decoder lengths and lags\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_index\n",
      "\u001b[0;31mAssertionError\u001b[0m: filters should not remove entries all entries - check encoder/decoder lengths and lags"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb927c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
